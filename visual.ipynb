{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m shoot_ray\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataset\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pil_to_binary\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import random\n",
    "import os\n",
    "\n",
    "from utils import shoot_ray\n",
    "from dataset.preprocessing import pil_to_binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the device\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "   device = 'mps'\n",
    "\n",
    "# Load the model and map it to the GPU\n",
    "model = torch.load(\"saved_models/model_full_old.pth\", map_location=device)\n",
    "ray_model = torch.load(\"saved_models/model_full_with_rays.pth\", map_location=device)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "#ray_model.eval()\n",
    "\n",
    "print(\"Model loaded onto\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 15\n",
    "image_files = glob.glob('./data_new/*.png')\n",
    "\n",
    "for run in range(num_runs):\n",
    "    # Randomly select one image\n",
    "    target_image_path = random.choice(image_files)\n",
    "    target_image = Image.open(target_image_path).convert('L')\n",
    "    target_image = pil_to_binary(target_image)\n",
    "    # Save target image to plots directory\n",
    "    os.makedirs(f\"./plots/{run}\", exist_ok=True)\n",
    "    plt.imsave(f\"./plots/{run}/target_image.png\", target_image, cmap='gray')\n",
    "\n",
    "    # Random agent simulation\n",
    "    # Assuming target_image is a numpy array or similar object\n",
    "    width, height = target_image.shape  # .shape is an attribute, not a method\n",
    "    print(width, height)\n",
    "    \n",
    "    num_samples = 15\n",
    "    i=0\n",
    "    \n",
    "    # Create a black image\n",
    "    image_black = np.zeros((width, height), dtype=np.int8)\n",
    "    image_with_rays = image_black.copy()\n",
    "    \n",
    "    while (i<num_samples):\n",
    "        # Generate random border and angle for ray shooting\n",
    "        border = np.random.randint(2 * (width + height))\n",
    "        angle = np.random.randint(360)\n",
    "        \n",
    "        # Perform ray shooting\n",
    "        pixels, hit = shoot_ray(target_image, border, angle)\n",
    "        \n",
    "        if hit is None:\n",
    "            continue\n",
    "        else:\n",
    "            image_black[hit[1], hit[0]] = 1\n",
    "            image_with_rays[hit[1], hit[0]] = 1\n",
    "            for pixel in pixels:\n",
    "                image_with_rays[pixel[1], pixel[0]] = -1\n",
    "    \n",
    "        print(f\"Selected Border Point (x, y): {border}\")\n",
    "        print(f\"Ray Shooting Angle: {angle} degrees\")\n",
    "    \n",
    "        print(f\"Ray Shooting Result: (x, y) = ({hit[1]}, {hit[0]})\")\n",
    "        print(f\"Angle for Ray: {angle} degrees\")\n",
    "        # Convert input array to a tensor suitable for the model\n",
    "        input_tensor = torch.tensor(image_black, dtype=torch.float32).unsqueeze(0)  # Add batch dimension\n",
    "        input_tensor_with_rays = torch.tensor(image_with_rays, dtype=torch.float32).unsqueeze(0)  # Add batch dimension\n",
    "        input_tensor = input_tensor.unsqueeze(1)  # Add channel dimension\n",
    "        input_tensor_with_rays = input_tensor_with_rays.unsqueeze(1)  # Add channel dimension\n",
    "        input_tensor = input_tensor.to(device)  # Move the tensor to the GPU\n",
    "        input_tensor_with_rays = input_tensor_with_rays.to(device)\n",
    "    \n",
    "        # Evaluate the model\n",
    "        with torch.no_grad():  # Disable gradient calculation for evaluation\n",
    "            output = model(input_tensor)  # Get the model's predictions\n",
    "            output_with_rays = ray_model(input_tensor_with_rays)\n",
    "    \n",
    "        # Convert the model output to a probability map and binary mask\n",
    "        output_image = output[0][0].cpu().numpy()  # Get the first output channel as a numpy array\n",
    "        output_image_with_rays = output_with_rays[0][0].cpu().numpy()  # Get the first output channel as a numpy array\n",
    "        binary_output = (output_image > 0.5).astype(np.uint8)  # Thresholding to create a binary mask\n",
    "        binary_output_with_rays = (output_image_with_rays > 0.5).astype(np.uint8)  # Thresholding to create a binary mask\n",
    "    \n",
    "        # Print shape of the output image and binary output for clarity\n",
    "        print(f\"Output Image Shape: {output_image.shape}\")\n",
    "        print(f\"Binary Mask Shape: {binary_output.shape}\")\n",
    "    \n",
    "        # Visualization using Matplotlib\n",
    "        plt.figure(figsize=(20, 5))\n",
    "    \n",
    "        \n",
    "    \n",
    "        found_points = np.where(image_black == 1)\n",
    "        plt.subplot(1, 5, 1)\n",
    "        plt.imshow(binary_output, cmap='gray')\n",
    "        #plt.scatter(found_points[1], found_points[0], color='green', s=10, label='Found Points')\n",
    "        #if x is not None and y is not None:\n",
    "        #    plt.scatter(y, x, color='red', s=25, label='Current Point')\n",
    "        plt.title('Binary Output with Points')\n",
    "        plt.axis('off')\n",
    "        # Add an arrow for the angle\n",
    "        #arrow_length = 20  # Adjust the length of the arrow\n",
    "        #arrow_dx = arrow_length * np.cos(np.radians(angle))  # Calculate arrow x component\n",
    "        #arrow_dy = arrow_length * np.sin(np.radians(angle))  # Calculate arrow y component\n",
    "        #plt.arrow(border[1], border[0], arrow_dy, arrow_dx, head_width=5, head_length=10, fc='red', ec='red', label='Angle')\n",
    "\n",
    "        #plot image with rays\n",
    "        plt.subplot(1, 5, 4)\n",
    "        plt.imshow(binary_output_with_rays, cmap='gray')\n",
    "        plt.title('Binary Output with Rays')\n",
    "        plt.axis('off')\n",
    "\n",
    "        #probability heatmap with rays\n",
    "        plt.subplot(1, 5, 5)\n",
    "        plt.imshow(output_image_with_rays, cmap='jet')\n",
    "        plt.title('Probability Heatmap with Rays')\n",
    "        plt.axis('off')\n",
    "    \n",
    "        # Probability heatmap\n",
    "        plt.subplot(1, 5, 2)\n",
    "        plt.imshow(output_image, cmap='jet')\n",
    "        plt.title('Probability Heatmap')\n",
    "        plt.axis('off')\n",
    "    \n",
    "        plt.subplot(1, 5, 3)\n",
    "        plt.imshow(target_image, cmap='gray')\n",
    "        plt.title('Target Image')\n",
    "        plt.axis('off')\n",
    "\n",
    "        #Save the plot to /plots\n",
    "        plt.savefig(f\"./plots/{run}/{i}.png\", bbox_inches='tight', dpi=100)\n",
    "        plt.close()\n",
    "\n",
    "        i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "PytorchStreamReader failed reading zip archive: failed finding central directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/model.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Carica il modello\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m \u001b[43mPPO\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\iacop\\anaconda3\\envs\\rl_ENV\\lib\\site-packages\\stable_baselines3\\common\\base_class.py:681\u001b[0m, in \u001b[0;36mBaseAlgorithm.load\u001b[1;34m(cls, path, env, device, custom_objects, print_system_info, force_reset, **kwargs)\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m== CURRENT SYSTEM INFO ==\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    679\u001b[0m     get_system_info()\n\u001b[1;32m--> 681\u001b[0m data, params, pytorch_variables \u001b[38;5;241m=\u001b[39m \u001b[43mload_from_zip_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprint_system_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprint_system_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo data found in the saved file\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    689\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo params found in the saved file\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\iacop\\anaconda3\\envs\\rl_ENV\\lib\\site-packages\\stable_baselines3\\common\\save_util.py:451\u001b[0m, in \u001b[0;36mload_from_zip_file\u001b[1;34m(load_path, load_data, custom_objects, device, verbose, print_system_info)\u001b[0m\n\u001b[0;32m    447\u001b[0m file_content\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    448\u001b[0m \u001b[38;5;66;03m# Load the parameters with the right ``map_location``.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;66;03m# Remove \".pth\" ending with splitext\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# Note(antonin): we cannot use weights_only=True, as it breaks with PyTorch 1.13, see GH#1911\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m th_object \u001b[38;5;241m=\u001b[39m \u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# \"tensors.pth\" was renamed \"pytorch_variables.pth\" in v0.9.0, see PR #138\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_path \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpytorch_variables.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m file_path \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensors.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;66;03m# PyTorch variables (not state_dicts)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\iacop\\anaconda3\\envs\\rl_ENV\\lib\\site-packages\\torch\\serialization.py:1326\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1324\u001b[0m orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n\u001b[0;32m   1325\u001b[0m overall_storage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1326\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_reader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_file\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m   1327\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_torchscript_zip(opened_zipfile):\n\u001b[0;32m   1328\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1329\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch.load\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m received a zip file that looks like a TorchScript archive\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1330\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m dispatching to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch.jit.load\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (call \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch.jit.load\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m directly to\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1331\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m silence this warning)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1332\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m   1333\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\iacop\\anaconda3\\envs\\rl_ENV\\lib\\site-packages\\torch\\serialization.py:671\u001b[0m, in \u001b[0;36m_open_zipfile_reader.__init__\u001b[1;34m(self, name_or_buffer)\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name_or_buffer) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 671\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: PytorchStreamReader failed reading zip archive: failed finding central directory"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "# ID del run salvato su WandB\n",
    "run_id = \"lk3fuasp\"  # Sostituisci con l'ID del tuo run salvato\n",
    "\n",
    "# Percorso del modello\n",
    "model_path = f\"models/{run_id}/model.zip\"\n",
    "\n",
    "# Carica il modello\n",
    "loaded_model = PPO.load(model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enviroment set up\n",
    "import wandb\n",
    "from stable_baselines3 import PPO\n",
    "from test_environment import TestEnvironment\n",
    "from test_env2 import TestEnvironment2\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecVideoRecorder\n",
    "\n",
    "env = TestEnvironment2((224, 224), 15, \"data_new/data_new\", render_mode = 'human')\n",
    "\n",
    "# Wrap the environment with DummyVecEnv (required by VecVideoRecorder)\n",
    "vec_env = DummyVecEnv([lambda: env])\n",
    "\n",
    "# Configure video recording\n",
    "video_folder = \"videos/\"\n",
    "video_length = 200  # Record the first 200 steps of each episode\n",
    "vec_env = VecVideoRecorder(\n",
    "    vec_env, \n",
    "    video_folder=video_folder, \n",
    "    record_video_trigger=lambda x: x % 100 == 0,  # Record every 10,000 steps\n",
    "    video_length=video_length,\n",
    "    name_prefix=\"ppo_agent\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 5\n",
    "counter = 0\n",
    "\n",
    "obs, info = env.reset()\n",
    "while ( counter < num_episodes):\n",
    "\n",
    "    action = env.action_space.sample()\n",
    "\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "    env.render()\n",
    "    \n",
    "    if done or truncated:\n",
    "        counter +=1\n",
    "        obs, info = env.reset()\n",
    "\n",
    "env.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
