{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import random\n",
    "import os\n",
    "\n",
    "from utils import shoot_ray\n",
    "from dataset.preprocessing import pil_to_binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the device\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "   device = 'mps'\n",
    "\n",
    "# Load the model and map it to the GPU\n",
    "model = torch.load(\"saved_models/model_full_old.pth\", map_location=device)\n",
    "ray_model = torch.load(\"saved_models/model_full_with_rays.pth\", map_location=device)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "#ray_model.eval()\n",
    "\n",
    "print(\"Model loaded onto\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 15\n",
    "image_files = glob.glob('./data_new/*.png')\n",
    "\n",
    "for run in range(num_runs):\n",
    "    # Randomly select one image\n",
    "    target_image_path = random.choice(image_files)\n",
    "    target_image = Image.open(target_image_path).convert('L')\n",
    "    target_image = pil_to_binary(target_image)\n",
    "    # Save target image to plots directory\n",
    "    os.makedirs(f\"./plots/{run}\", exist_ok=True)\n",
    "    plt.imsave(f\"./plots/{run}/target_image.png\", target_image, cmap='gray')\n",
    "\n",
    "    # Random agent simulation\n",
    "    # Assuming target_image is a numpy array or similar object\n",
    "    width, height = target_image.shape  # .shape is an attribute, not a method\n",
    "    print(width, height)\n",
    "    \n",
    "    num_samples = 15\n",
    "    i=0\n",
    "    \n",
    "    # Create a black image\n",
    "    image_black = np.zeros((width, height), dtype=np.int8)\n",
    "    image_with_rays = image_black.copy()\n",
    "    \n",
    "    while (i<num_samples):\n",
    "        # Generate random border and angle for ray shooting\n",
    "        border = np.random.randint(2 * (width + height))\n",
    "        angle = np.random.randint(360)\n",
    "        \n",
    "        # Perform ray shooting\n",
    "        pixels, hit = shoot_ray(target_image, border, angle)\n",
    "        \n",
    "        if hit is None:\n",
    "            continue\n",
    "        else:\n",
    "            image_black[hit[1], hit[0]] = 1\n",
    "            image_with_rays[hit[1], hit[0]] = 1\n",
    "            for pixel in pixels:\n",
    "                image_with_rays[pixel[1], pixel[0]] = -1\n",
    "    \n",
    "        print(f\"Selected Border Point (x, y): {border}\")\n",
    "        print(f\"Ray Shooting Angle: {angle} degrees\")\n",
    "    \n",
    "        print(f\"Ray Shooting Result: (x, y) = ({hit[1]}, {hit[0]})\")\n",
    "        print(f\"Angle for Ray: {angle} degrees\")\n",
    "        # Convert input array to a tensor suitable for the model\n",
    "        input_tensor = torch.tensor(image_black, dtype=torch.float32).unsqueeze(0)  # Add batch dimension\n",
    "        input_tensor_with_rays = torch.tensor(image_with_rays, dtype=torch.float32).unsqueeze(0)  # Add batch dimension\n",
    "        input_tensor = input_tensor.unsqueeze(1)  # Add channel dimension\n",
    "        input_tensor_with_rays = input_tensor_with_rays.unsqueeze(1)  # Add channel dimension\n",
    "        input_tensor = input_tensor.to(device)  # Move the tensor to the GPU\n",
    "        input_tensor_with_rays = input_tensor_with_rays.to(device)\n",
    "    \n",
    "        # Evaluate the model\n",
    "        with torch.no_grad():  # Disable gradient calculation for evaluation\n",
    "            output = model(input_tensor)  # Get the model's predictions\n",
    "            output_with_rays = ray_model(input_tensor_with_rays)\n",
    "    \n",
    "        # Convert the model output to a probability map and binary mask\n",
    "        output_image = output[0][0].cpu().numpy()  # Get the first output channel as a numpy array\n",
    "        output_image_with_rays = output_with_rays[0][0].cpu().numpy()  # Get the first output channel as a numpy array\n",
    "        binary_output = (output_image > 0.5).astype(np.uint8)  # Thresholding to create a binary mask\n",
    "        binary_output_with_rays = (output_image_with_rays > 0.5).astype(np.uint8)  # Thresholding to create a binary mask\n",
    "    \n",
    "        # Print shape of the output image and binary output for clarity\n",
    "        print(f\"Output Image Shape: {output_image.shape}\")\n",
    "        print(f\"Binary Mask Shape: {binary_output.shape}\")\n",
    "    \n",
    "        # Visualization using Matplotlib\n",
    "        plt.figure(figsize=(20, 5))\n",
    "    \n",
    "        \n",
    "    \n",
    "        found_points = np.where(image_black == 1)\n",
    "        plt.subplot(1, 5, 1)\n",
    "        plt.imshow(binary_output, cmap='gray')\n",
    "        #plt.scatter(found_points[1], found_points[0], color='green', s=10, label='Found Points')\n",
    "        #if x is not None and y is not None:\n",
    "        #    plt.scatter(y, x, color='red', s=25, label='Current Point')\n",
    "        plt.title('Binary Output with Points')\n",
    "        plt.axis('off')\n",
    "        # Add an arrow for the angle\n",
    "        #arrow_length = 20  # Adjust the length of the arrow\n",
    "        #arrow_dx = arrow_length * np.cos(np.radians(angle))  # Calculate arrow x component\n",
    "        #arrow_dy = arrow_length * np.sin(np.radians(angle))  # Calculate arrow y component\n",
    "        #plt.arrow(border[1], border[0], arrow_dy, arrow_dx, head_width=5, head_length=10, fc='red', ec='red', label='Angle')\n",
    "\n",
    "        #plot image with rays\n",
    "        plt.subplot(1, 5, 4)\n",
    "        plt.imshow(binary_output_with_rays, cmap='gray')\n",
    "        plt.title('Binary Output with Rays')\n",
    "        plt.axis('off')\n",
    "\n",
    "        #probability heatmap with rays\n",
    "        plt.subplot(1, 5, 5)\n",
    "        plt.imshow(output_image_with_rays, cmap='jet')\n",
    "        plt.title('Probability Heatmap with Rays')\n",
    "        plt.axis('off')\n",
    "    \n",
    "        # Probability heatmap\n",
    "        plt.subplot(1, 5, 2)\n",
    "        plt.imshow(output_image, cmap='jet')\n",
    "        plt.title('Probability Heatmap')\n",
    "        plt.axis('off')\n",
    "    \n",
    "        plt.subplot(1, 5, 3)\n",
    "        plt.imshow(target_image, cmap='gray')\n",
    "        plt.title('Target Image')\n",
    "        plt.axis('off')\n",
    "\n",
    "        #Save the plot to /plots\n",
    "        plt.savefig(f\"./plots/{run}/{i}.png\", bbox_inches='tight', dpi=100)\n",
    "        plt.close()\n",
    "\n",
    "        i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "# ID del run salvato su WandB\n",
    "run_id = \"<wandb_run_id>\"  # Sostituisci con l'ID del tuo run salvato\n",
    "\n",
    "# Percorso del modello\n",
    "model_path = f\"models/{run_id}/model.zip\"\n",
    "\n",
    "# Carica il modello\n",
    "loaded_model = PPO.load(model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enviroment set up\n",
    "import wandb\n",
    "from stable_baselines3 import PPO\n",
    "from test_environment import TestEnvironment\n",
    "from test_env2 import TestEnvironment2\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecVideoRecorder\n",
    "\n",
    "env = TestEnvironment2((224, 224), 15, \"data_new/data_new\", render_mode = 'human')\n",
    "\n",
    "# Wrap the environment with DummyVecEnv (required by VecVideoRecorder)\n",
    "vec_env = DummyVecEnv([lambda: env])\n",
    "\n",
    "# Configure video recording\n",
    "video_folder = \"videos/\"\n",
    "video_length = 200  # Record the first 200 steps of each episode\n",
    "vec_env = VecVideoRecorder(\n",
    "    vec_env, \n",
    "    video_folder=video_folder, \n",
    "    record_video_trigger=lambda x: x % 100 == 0,  # Record every 10,000 steps\n",
    "    video_length=video_length,\n",
    "    name_prefix=\"ppo_agent\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 5\n",
    "counter = 0\n",
    "\n",
    "obs, info = env.reset()\n",
    "while ( counter < num_episodes):\n",
    "\n",
    "    action = env.action_space.sample()\n",
    "\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "    env.render()\n",
    "    \n",
    "    if done or truncated:\n",
    "        counter +=1\n",
    "        obs, info = env.reset()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
